{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline to put embeddings to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "from config import Config\n",
    "from embeddings import pass_through\n",
    "from embeddings import load_model_artifact\n",
    "from embeddings import get_all_issue_text\n",
    "import dill as dpickle\n",
    "import os\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "class IssuesLoader(object):\n",
    "    \n",
    "    def __init__(self, yaml_path=None):\n",
    "        if not yaml_path:\n",
    "            if 'YAML_PATH' in os.environ:\n",
    "                print('yaml_path not supplied; check environment variable')\n",
    "                yaml_path = os.getenv('YAML_PATH')\n",
    "            else:\n",
    "                print('yaml_path not supplied; using the default')\n",
    "                yaml_path = 'issue_label_bot.yaml'\n",
    "        self.yaml_path = yaml_path\n",
    "        self.load_yaml()\n",
    "\n",
    "    def load_yaml(self):\n",
    "        config = Config(self.yaml_path)\n",
    "        self.repo_owner = config.repo_owner\n",
    "        self.repo_name = config.repo_name\n",
    "\n",
    "        self.bucket_name = config.emb_bucket_name\n",
    "        self.emb_file = config.emb_local_path\n",
    "        self.emb_dest = config.emb_gcs_path\n",
    "\n",
    "    def load_lang_model(self):\n",
    "        return load_model_artifact()\n",
    "\n",
    "    def save_issue_embeddings(self):\n",
    "        # check whether embeddings exist in gcs\n",
    "        if self.check_embeddings_in_gcs():\n",
    "            return\n",
    "\n",
    "        inference_wrapper = self.load_lang_model()\n",
    "        data = get_all_issue_text(owner=self.repo_owner, repo=self.repo_name,\n",
    "                                  inf_wrapper=inference_wrapper)\n",
    "        with open(self.emb_file, 'wb') as f:\n",
    "            dpickle.dump(data, f)\n",
    "\n",
    "        self.upload_embeddings_to_gcs()\n",
    "\n",
    "    def check_embeddings_in_gcs(self):\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.get_bucket(self.bucket_name)\n",
    "        return storage.Blob(bucket=bucket, name=self.emb_dest).exists(storage_client)\n",
    "\n",
    "    def upload_embeddings_to_gcs(self):\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.get_bucket(self.bucket_name)\n",
    "        blob = bucket.blob(self.emb_dest)\n",
    "        blob.upload_from_filename(self.emb_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run locally to test the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = '../issue_label_bot.yaml'\n",
    "ldr = IssuesLoader(yaml_path=yaml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/207 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 207 issues.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [10:40<00:00,  2.04s/it]\n"
     ]
    }
   ],
   "source": [
    "ldr.save_issue_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not do anything because embeddings exist\n",
    "ldr.save_issue_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create entry point using fairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairing.preprocessors.converted_notebook import ConvertNotebookPreprocessorWithFire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('Issues_Loader.py'), 'config.py', 'inference.py', 'embeddings.py']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = ConvertNotebookPreprocessorWithFire('IssuesLoader')\n",
    "\n",
    "if not preprocessor.input_files:\n",
    "    preprocessor.input_files = set()\n",
    "input_files = ['embeddings.py', 'inference.py', 'config.py']\n",
    "preprocessor.input_files =  set([os.path.normpath(f) for f in input_files])\n",
    "preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
